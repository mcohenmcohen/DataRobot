{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built by Kayne and given to me on March 11, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import timedelta, date, datetime, date\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datarobot as dr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingest data, remove SIZE_ACT and re-format dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>date_purchase_request</th>\n",
       "      <th>purchase_no</th>\n",
       "      <th>purchase_item_no</th>\n",
       "      <th>line_number</th>\n",
       "      <th>option_number</th>\n",
       "      <th>size_act</th>\n",
       "      <th>brand</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>category</th>\n",
       "      <th>category_group</th>\n",
       "      <th>size</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MTAMG</td>\n",
       "      <td>MTKKP</td>\n",
       "      <td>18</td>\n",
       "      <td>V by Very Curve</td>\n",
       "      <td>womens_jeans</td>\n",
       "      <td>jeans</td>\n",
       "      <td>bottoms</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MTAMG</td>\n",
       "      <td>MTKKP</td>\n",
       "      <td>18</td>\n",
       "      <td>V by Very Curve</td>\n",
       "      <td>womens_jeans</td>\n",
       "      <td>jeans</td>\n",
       "      <td>bottoms</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MTAMG</td>\n",
       "      <td>MTKKP</td>\n",
       "      <td>18</td>\n",
       "      <td>V by Very Curve</td>\n",
       "      <td>womens_jeans</td>\n",
       "      <td>jeans</td>\n",
       "      <td>bottoms</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MTAMG</td>\n",
       "      <td>MTKKP</td>\n",
       "      <td>18</td>\n",
       "      <td>V by Very Curve</td>\n",
       "      <td>womens_jeans</td>\n",
       "      <td>jeans</td>\n",
       "      <td>bottoms</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MTAMG</td>\n",
       "      <td>MTKKP</td>\n",
       "      <td>18</td>\n",
       "      <td>V by Very Curve</td>\n",
       "      <td>womens_jeans</td>\n",
       "      <td>jeans</td>\n",
       "      <td>bottoms</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            cust_id date_purchase_request  purchase_no  \\\n",
       "0  00000419c5c8eebdb9c91c827a18ea4f            2019-05-09            1   \n",
       "1  00000419c5c8eebdb9c91c827a18ea4f            2019-05-09            1   \n",
       "2  00000419c5c8eebdb9c91c827a18ea4f            2019-05-09            1   \n",
       "3  00000419c5c8eebdb9c91c827a18ea4f            2019-05-09            1   \n",
       "4  00000419c5c8eebdb9c91c827a18ea4f            2019-05-09            1   \n",
       "\n",
       "   purchase_item_no line_number option_number size_act            brand  \\\n",
       "0                 1       MTAMG         MTKKP       18  V by Very Curve   \n",
       "1                 1       MTAMG         MTKKP       18  V by Very Curve   \n",
       "2                 1       MTAMG         MTKKP       18  V by Very Curve   \n",
       "3                 1       MTAMG         MTKKP       18  V by Very Curve   \n",
       "4                 1       MTAMG         MTKKP       18  V by Very Curve   \n",
       "\n",
       "   sub_category category category_group size  response  \n",
       "0  womens_jeans    jeans        bottoms   16         0  \n",
       "1  womens_jeans    jeans        bottoms   18         1  \n",
       "2  womens_jeans    jeans        bottoms   20         0  \n",
       "3  womens_jeans    jeans        bottoms   22         0  \n",
       "4  womens_jeans    jeans        bottoms   24         0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('transaction_data_h.csv',header=0)\n",
    "df[\"date_purchase_request\"] = pd.to_datetime(df['date_purchase_request'],format='%Y-%m-%d',errors='coerce')\n",
    "df = df.drop_duplicates()\n",
    "df = df.groupby(df.columns.to_list()[:-1]).sum().reset_index()\n",
    "df.head()\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366556"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custIds = df[\"cust_id\"].drop_duplicates()\n",
    "sizes = df[\"size\"].drop_duplicates() \n",
    "items = df[\"line_number\"].drop_duplicates()\n",
    "len(custIds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add on new features on from previous purchase info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Prev_Rank</th>\n",
       "      <th>date_purchase_request</th>\n",
       "      <th>prev_size</th>\n",
       "      <th>prev_line_number</th>\n",
       "      <th>prev_date_purchase_request</th>\n",
       "      <th>Trans_Rank</th>\n",
       "      <th>Trans_Rank_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001ca92bcd0a45aed94b61338c2bb0d</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-08-28</td>\n",
       "      <td>18</td>\n",
       "      <td>NHLM3</td>\n",
       "      <td>2019-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>L1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001ca92bcd0a45aed94b61338c2bb0d</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-08-28</td>\n",
       "      <td>18</td>\n",
       "      <td>NHLKY</td>\n",
       "      <td>2019-04-30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>L2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000226ed2106ff2769f2cf210ec5e2ac</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-09-28</td>\n",
       "      <td>XS</td>\n",
       "      <td>LTQTE</td>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>L1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000277e1669671b024277cf1fc1ee7a9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-10-20</td>\n",
       "      <td>10</td>\n",
       "      <td>MKALP</td>\n",
       "      <td>2018-10-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>L1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000277e1669671b024277cf1fc1ee7a9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>10</td>\n",
       "      <td>MKALP</td>\n",
       "      <td>2018-10-17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>L2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            cust_id  Rank  Prev_Rank date_purchase_request  \\\n",
       "0  0001ca92bcd0a45aed94b61338c2bb0d     2          1            2019-08-28   \n",
       "1  0001ca92bcd0a45aed94b61338c2bb0d     2          1            2019-08-28   \n",
       "2  000226ed2106ff2769f2cf210ec5e2ac     2          1            2019-09-28   \n",
       "3  000277e1669671b024277cf1fc1ee7a9     2          1            2018-10-20   \n",
       "4  000277e1669671b024277cf1fc1ee7a9     3          1            2019-02-26   \n",
       "\n",
       "  prev_size prev_line_number prev_date_purchase_request  Trans_Rank  \\\n",
       "0        18            NHLM3                 2019-04-30         1.0   \n",
       "1        18            NHLKY                 2019-04-30         2.0   \n",
       "2        XS            LTQTE                 2017-12-18         1.0   \n",
       "3        10            MKALP                 2018-10-17         1.0   \n",
       "4        10            MKALP                 2018-10-17         2.0   \n",
       "\n",
       "  Trans_Rank_C  \n",
       "0         L1.0  \n",
       "1         L2.0  \n",
       "2         L1.0  \n",
       "3         L1.0  \n",
       "4         L2.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCombos = df[[\"cust_id\",\"date_purchase_request\",\"line_number\",\"size\"]][df[\"response\"] == 1].drop_duplicates()\n",
    "grouped =  allCombos.groupby(['cust_id'])\n",
    "allCombos['Rank'] = grouped['date_purchase_request'].transform(lambda x: pd.factorize(x, sort=True)[0]+1)\n",
    "allCombos['key'] = 0\n",
    "\n",
    "cross = pd.merge(allCombos[[\"cust_id\",\"key\",\"Rank\"]], allCombos[[\"cust_id\",\"key\",\"Rank\"]],on=[\"cust_id\",'key']).rename(columns={\"Rank_x\":\"Rank\",\"Rank_y\":\"Prev_Rank\"})\n",
    "cross = cross[(cross[\"Rank\"] > cross[\"Prev_Rank\"]) & (cross[\"Rank\"] >= 1) & (cross[\"Prev_Rank\"] >= 1)].drop(\"key\",axis=1).drop_duplicates()\n",
    "\n",
    "final = cross.merge(allCombos[[\"cust_id\",\"Rank\",\"date_purchase_request\"]].drop_duplicates(),on=[\"cust_id\",\"Rank\"],how=\"left\")\n",
    "final = final.merge(allCombos[[\"cust_id\",\"Rank\",\"size\",\"line_number\",\"date_purchase_request\"]].rename(columns={\"Rank\":\"Prev_Rank\",\"size\":\"prev_size\",\"date_purchase_request\":\"prev_date_purchase_request\",\"line_number\":\"prev_line_number\"}).drop_duplicates(),on=[\"cust_id\",\"Prev_Rank\"],how=\"left\")\n",
    "final['Trans_Rank'] = final.groupby([\"cust_id\",\"Rank\"])[\"prev_date_purchase_request\"].rank(method='first',ascending=False)\n",
    "final['Trans_Rank_C'] = \"L\"+final['Trans_Rank'].astype(str)\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add on new features for the previous 5 purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>date_purchase_request</th>\n",
       "      <th>prev_line_number_L1.0</th>\n",
       "      <th>prev_line_number_L10.0</th>\n",
       "      <th>prev_line_number_L11.0</th>\n",
       "      <th>prev_line_number_L12.0</th>\n",
       "      <th>prev_line_number_L13.0</th>\n",
       "      <th>prev_line_number_L14.0</th>\n",
       "      <th>prev_line_number_L15.0</th>\n",
       "      <th>prev_line_number_L16.0</th>\n",
       "      <th>...</th>\n",
       "      <th>prev_size_L48.0</th>\n",
       "      <th>prev_size_L49.0</th>\n",
       "      <th>prev_size_L5.0</th>\n",
       "      <th>prev_size_L50.0</th>\n",
       "      <th>prev_size_L6.0</th>\n",
       "      <th>prev_size_L7.0</th>\n",
       "      <th>prev_size_L8.0</th>\n",
       "      <th>prev_size_L9.0</th>\n",
       "      <th>last_5_line_number</th>\n",
       "      <th>last_5_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001ca92bcd0a45aed94b61338c2bb0d</td>\n",
       "      <td>2019-08-28</td>\n",
       "      <td>NHLM3</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>NHLM3 NHLKY</td>\n",
       "      <td>18 18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000226ed2106ff2769f2cf210ec5e2ac</td>\n",
       "      <td>2019-09-28</td>\n",
       "      <td>LTQTE</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>LTQTE</td>\n",
       "      <td>XS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000277e1669671b024277cf1fc1ee7a9</td>\n",
       "      <td>2018-10-20</td>\n",
       "      <td>MKALP</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>MKALP</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000277e1669671b024277cf1fc1ee7a9</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>MMV3Y</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>MMV3Y MKALP</td>\n",
       "      <td>10 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00029190767aa56d9b3bd825a972ebcd</td>\n",
       "      <td>2018-11-06</td>\n",
       "      <td>MR3YG</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>MR3YG</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            cust_id date_purchase_request  \\\n",
       "0  0001ca92bcd0a45aed94b61338c2bb0d            2019-08-28   \n",
       "1  000226ed2106ff2769f2cf210ec5e2ac            2019-09-28   \n",
       "2  000277e1669671b024277cf1fc1ee7a9            2018-10-20   \n",
       "3  000277e1669671b024277cf1fc1ee7a9            2019-02-26   \n",
       "4  00029190767aa56d9b3bd825a972ebcd            2018-11-06   \n",
       "\n",
       "  prev_line_number_L1.0 prev_line_number_L10.0 prev_line_number_L11.0  \\\n",
       "0                 NHLM3                    N/A                    N/A   \n",
       "1                 LTQTE                    N/A                    N/A   \n",
       "2                 MKALP                    N/A                    N/A   \n",
       "3                 MMV3Y                    N/A                    N/A   \n",
       "4                 MR3YG                    N/A                    N/A   \n",
       "\n",
       "  prev_line_number_L12.0 prev_line_number_L13.0 prev_line_number_L14.0  \\\n",
       "0                    N/A                    N/A                    N/A   \n",
       "1                    N/A                    N/A                    N/A   \n",
       "2                    N/A                    N/A                    N/A   \n",
       "3                    N/A                    N/A                    N/A   \n",
       "4                    N/A                    N/A                    N/A   \n",
       "\n",
       "  prev_line_number_L15.0 prev_line_number_L16.0  ... prev_size_L48.0  \\\n",
       "0                    N/A                    N/A  ...             N/A   \n",
       "1                    N/A                    N/A  ...             N/A   \n",
       "2                    N/A                    N/A  ...             N/A   \n",
       "3                    N/A                    N/A  ...             N/A   \n",
       "4                    N/A                    N/A  ...             N/A   \n",
       "\n",
       "  prev_size_L49.0 prev_size_L5.0 prev_size_L50.0 prev_size_L6.0  \\\n",
       "0             N/A            N/A             N/A            N/A   \n",
       "1             N/A            N/A             N/A            N/A   \n",
       "2             N/A            N/A             N/A            N/A   \n",
       "3             N/A            N/A             N/A            N/A   \n",
       "4             N/A            N/A             N/A            N/A   \n",
       "\n",
       "  prev_size_L7.0 prev_size_L8.0 prev_size_L9.0 last_5_line_number last_5_size  \n",
       "0            N/A            N/A            N/A     NHLM3 NHLKY       18 18     \n",
       "1            N/A            N/A            N/A          LTQTE          XS      \n",
       "2            N/A            N/A            N/A          MKALP          10      \n",
       "3            N/A            N/A            N/A     MMV3Y MKALP       10 10     \n",
       "4            N/A            N/A            N/A          MR3YG           8      \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot1 = final[final[\"Trans_Rank\"] <= 50]\n",
    "pivot1 = pd.pivot_table(pivot1, index=['cust_id',\"Rank\",\"date_purchase_request\"],columns='Trans_Rank_C',values=[\"prev_size\",\"prev_line_number\"],aggfunc='first',fill_value=\"N/A\")\n",
    "pivot1.reset_index(inplace=True)\n",
    "pivot1.columns = [\"_\".join(x) for x in pivot1.columns.ravel()]\n",
    "pivot1 = pivot1.rename(columns={\"cust_id_\":\"cust_id\",\"date_purchase_request_\":\"date_purchase_request\"}).drop(columns=[\"Rank_\"],axis=1)\n",
    "pivot1[\"last_5_line_number\"] = (pivot1[\"prev_line_number_L1.0\"].astype(str)+\" \"+pivot1[\"prev_line_number_L2.0\"].astype(str)+\" \"+pivot1[\"prev_line_number_L3.0\"].astype(str)+\" \"+pivot1[\"prev_line_number_L4.0\"].astype(str)+\" \"+pivot1[\"prev_line_number_L5.0\"].astype(str)).str.replace('N/A','')\n",
    "pivot1[\"last_5_size\"] = (pivot1[\"prev_size_L1.0\"].astype(str)+\" \"+pivot1[\"prev_size_L2.0\"].astype(str)+\" \"+pivot1[\"prev_size_L3.0\"].astype(str)+\" \"+pivot1[\"prev_size_L4.0\"].astype(str)+\" \"+pivot1[\"prev_size_L5.0\"].astype(str)).replace({'N/A':''}).str.replace('N/A','')\n",
    "pivot1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(pivot1,on=[\"cust_id\",\"date_purchase_request\"],how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add on features for every size very bought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prev_size</th>\n",
       "      <th>cust_id</th>\n",
       "      <th>Rank</th>\n",
       "      <th>date_purchase_request</th>\n",
       "      <th>size_10 D/DD</th>\n",
       "      <th>size_10 E/F</th>\n",
       "      <th>size_10-12</th>\n",
       "      <th>size_10=28</th>\n",
       "      <th>size_10=M</th>\n",
       "      <th>size_10=MREGULAR</th>\n",
       "      <th>size_10=S</th>\n",
       "      <th>...</th>\n",
       "      <th>size_XS=6</th>\n",
       "      <th>size_XXL</th>\n",
       "      <th>size_XXL/18</th>\n",
       "      <th>size_XXL=16</th>\n",
       "      <th>size_XXL=16REGULAR</th>\n",
       "      <th>size_XXLD/E</th>\n",
       "      <th>size_XXS</th>\n",
       "      <th>size_XXS/6</th>\n",
       "      <th>size_XXXL</th>\n",
       "      <th>size_XXXXL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001ca92bcd0a45aed94b61338c2bb0d</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000226ed2106ff2769f2cf210ec5e2ac</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-09-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000277e1669671b024277cf1fc1ee7a9</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-10-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000277e1669671b024277cf1fc1ee7a9</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00029190767aa56d9b3bd825a972ebcd</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-11-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 523 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "prev_size                           cust_id  Rank date_purchase_request  \\\n",
       "0          0001ca92bcd0a45aed94b61338c2bb0d     2            2019-08-28   \n",
       "1          000226ed2106ff2769f2cf210ec5e2ac     2            2019-09-28   \n",
       "2          000277e1669671b024277cf1fc1ee7a9     2            2018-10-20   \n",
       "3          000277e1669671b024277cf1fc1ee7a9     3            2019-02-26   \n",
       "4          00029190767aa56d9b3bd825a972ebcd     2            2018-11-06   \n",
       "\n",
       "prev_size  size_10 D/DD  size_10 E/F  size_10-12  size_10=28  size_10=M  \\\n",
       "0                     0            0           0           0          0   \n",
       "1                     0            0           0           0          0   \n",
       "2                     0            0           0           0          0   \n",
       "3                     0            0           0           0          0   \n",
       "4                     0            0           0           0          0   \n",
       "\n",
       "prev_size  size_10=MREGULAR  size_10=S  ...  size_XS=6  size_XXL  size_XXL/18  \\\n",
       "0                         0          0  ...          0         0            0   \n",
       "1                         0          0  ...          0         0            0   \n",
       "2                         0          0  ...          0         0            0   \n",
       "3                         0          0  ...          0         0            0   \n",
       "4                         0          0  ...          0         0            0   \n",
       "\n",
       "prev_size  size_XXL=16  size_XXL=16REGULAR  size_XXLD/E  size_XXS  size_XXS/6  \\\n",
       "0                    0                   0            0         0           0   \n",
       "1                    0                   0            0         0           0   \n",
       "2                    0                   0            0         0           0   \n",
       "3                    0                   0            0         0           0   \n",
       "4                    0                   0            0         0           0   \n",
       "\n",
       "prev_size  size_XXXL  size_XXXXL  \n",
       "0                  0           0  \n",
       "1                  0           0  \n",
       "2                  0           0  \n",
       "3                  0           0  \n",
       "4                  0           0  \n",
       "\n",
       "[5 rows x 523 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot2 = final.groupby([\"cust_id\",\"Rank\",\"date_purchase_request\",\"prev_size\"]).size().reset_index(name='counts')\n",
    "pivot2 = pd.pivot_table(pivot2, index=['cust_id',\"Rank\",\"date_purchase_request\"],columns='prev_size',values=\"counts\",fill_value=0)\n",
    "pivot2 = pivot2[pivot2.columns.to_list()[3:]].add_prefix('size_')\n",
    "pivot2.reset_index(inplace=True)\n",
    "pivot2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(pivot2,on=[\"cust_id\",\"date_purchase_request\"],how=\"left\")\\\n",
    "            .drop([\"size_act\",\"option_number\",\"purchase_item_no\",\"purchase_no\",\"date_purchase_request\"],axis=1)\\\n",
    "            .fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>date_purchase_request</th>\n",
       "      <th>purchase_no</th>\n",
       "      <th>purchase_item_no</th>\n",
       "      <th>line_number</th>\n",
       "      <th>option_number</th>\n",
       "      <th>size_act</th>\n",
       "      <th>brand</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>category</th>\n",
       "      <th>...</th>\n",
       "      <th>size_XS=6</th>\n",
       "      <th>size_XXL</th>\n",
       "      <th>size_XXL/18</th>\n",
       "      <th>size_XXL=16</th>\n",
       "      <th>size_XXL=16REGULAR</th>\n",
       "      <th>size_XXLD/E</th>\n",
       "      <th>size_XXS</th>\n",
       "      <th>size_XXS/6</th>\n",
       "      <th>size_XXXL</th>\n",
       "      <th>size_XXXXL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MTAMG</td>\n",
       "      <td>MTKKP</td>\n",
       "      <td>18</td>\n",
       "      <td>V by Very Curve</td>\n",
       "      <td>womens_jeans</td>\n",
       "      <td>jeans</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MTAMG</td>\n",
       "      <td>MTKKP</td>\n",
       "      <td>18</td>\n",
       "      <td>V by Very Curve</td>\n",
       "      <td>womens_jeans</td>\n",
       "      <td>jeans</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MTAMG</td>\n",
       "      <td>MTKKP</td>\n",
       "      <td>18</td>\n",
       "      <td>V by Very Curve</td>\n",
       "      <td>womens_jeans</td>\n",
       "      <td>jeans</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MTAMG</td>\n",
       "      <td>MTKKP</td>\n",
       "      <td>18</td>\n",
       "      <td>V by Very Curve</td>\n",
       "      <td>womens_jeans</td>\n",
       "      <td>jeans</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MTAMG</td>\n",
       "      <td>MTKKP</td>\n",
       "      <td>18</td>\n",
       "      <td>V by Very Curve</td>\n",
       "      <td>womens_jeans</td>\n",
       "      <td>jeans</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 636 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            cust_id date_purchase_request  purchase_no  \\\n",
       "0  00000419c5c8eebdb9c91c827a18ea4f            2019-05-09            1   \n",
       "1  00000419c5c8eebdb9c91c827a18ea4f            2019-05-09            1   \n",
       "2  00000419c5c8eebdb9c91c827a18ea4f            2019-05-09            1   \n",
       "3  00000419c5c8eebdb9c91c827a18ea4f            2019-05-09            1   \n",
       "4  00000419c5c8eebdb9c91c827a18ea4f            2019-05-09            1   \n",
       "\n",
       "   purchase_item_no line_number option_number size_act            brand  \\\n",
       "0                 1       MTAMG         MTKKP       18  V by Very Curve   \n",
       "1                 1       MTAMG         MTKKP       18  V by Very Curve   \n",
       "2                 1       MTAMG         MTKKP       18  V by Very Curve   \n",
       "3                 1       MTAMG         MTKKP       18  V by Very Curve   \n",
       "4                 1       MTAMG         MTKKP       18  V by Very Curve   \n",
       "\n",
       "   sub_category category  ... size_XS=6 size_XXL  size_XXL/18 size_XXL=16  \\\n",
       "0  womens_jeans    jeans  ...       0.0      0.0          0.0         0.0   \n",
       "1  womens_jeans    jeans  ...       0.0      0.0          0.0         0.0   \n",
       "2  womens_jeans    jeans  ...       0.0      0.0          0.0         0.0   \n",
       "3  womens_jeans    jeans  ...       0.0      0.0          0.0         0.0   \n",
       "4  womens_jeans    jeans  ...       0.0      0.0          0.0         0.0   \n",
       "\n",
       "  size_XXL=16REGULAR size_XXLD/E size_XXS size_XXS/6 size_XXXL size_XXXXL  \n",
       "0                0.0         0.0      0.0        0.0       0.0        0.0  \n",
       "1                0.0         0.0      0.0        0.0       0.0        0.0  \n",
       "2                0.0         0.0      0.0        0.0       0.0        0.0  \n",
       "3                0.0         0.0      0.0        0.0       0.0        0.0  \n",
       "4                0.0         0.0      0.0        0.0       0.0        0.0  \n",
       "\n",
       "[5 rows x 636 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop([\"size_act\",\"option_number\",\"purchase_item_no\",\"purchase_no\",\"date_purchase_request\"],axis=1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, score = np.split(df.sample(frac=1), [int(.7*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCombos = df[[\"cust_id\",\"line_number\"]].drop_duplicates()\n",
    "allCombos.head()\n",
    "\n",
    "train, score = np.split(allCombos.sample(frac=1), [int(.7*len(allCombos))])\n",
    "\n",
    "train = df.merge(train,on=[\"cust_id\",\"line_number\"],how=\"inner\")\n",
    "score = df.merge(score,on=[\"cust_id\",\"line_number\"],how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Have a look at distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9166698\n",
       "1    1204970\n",
       "Name: response, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.response.value_counts()\n",
    "#train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3926495\n",
       "1     516410\n",
       "Name: response, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.response.value_counts()\n",
    "#score.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"transaction_data_h_train.csv.gz\",index=False,compression='gzip')\n",
    "score.to_csv(\"transaction_data_h_score.csv.gz\",index=False,compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataRobot model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to DR and run Autopilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datarobot.rest.RESTClientObject at 0x7f86a3d03590>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.Client(config_path='drconfig.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#primary_dataset = dr.Dataset.create_from_in_memory_data(train)\n",
    "primary_dataset = dr.Dataset.create_from_file(file_path=\"transaction_data_h_train.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proj = dr.Project.get(\"5f11e3c39e69e50184d8b861\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = dr.Project.create_from_dataset(primary_dataset.id,project_name='TVG_SizeRecc_withL50Purchases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proj = dr.Project.create(train,project_name='TVG_SizeRecc',max_wait=3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.05"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout = 8\n",
    "validation = 8\n",
    "kFolds = 5\n",
    "#CVDetails = dr.StratifiedCV(holdout_pct=holdout,reps=kFolds)\n",
    "CVDetails = dr.StratifiedTVH(holdout_pct=holdout, validation_pct=validation,)\n",
    "advancedOptions = dr.AdvancedOptions(smart_downsampled=False)\n",
    "\n",
    "smidgin = 0.05\n",
    "#cutoff = (100-holdout)*((kFolds-1)/kFolds)+smidgin\n",
    "cutoff = (100-holdout-validation)+smidgin\n",
    "cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Project(TVG_SizeRecc_withL50Purchases)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj.set_target(target='response',mode=dr.enums.AUTOPILOT_MODE.FULL_AUTO,worker_count=-1,partitioning_method=CVDetails,advanced_options=advancedOptions,max_wait=3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the deepCTR models and run those as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Blueprint(eXtreme Gradient Boosted Trees Classifier with Early Stopping (learning rate =0.43) (Fast Feature Binning)),\n",
       " Blueprint(Elastic-Net Classifier with Naive Bayes Feature Weighting (L2)),\n",
       " Blueprint(TensorFlow Deep Learning Classifier),\n",
       " Blueprint(eXtreme Gradient Boosted Trees Classifier with Early Stopping (learning rate =0.01) (Fast Feature Binning)),\n",
       " Blueprint(Gradient Boosted Greedy Trees Classifier with Early Stopping),\n",
       " Blueprint(eXtreme Gradient Boosted Trees Classifier with Early Stopping (learning rate =0.01) (Fast Feature Binning)),\n",
       " Blueprint(Light Gradient Boosting on ElasticNet Predictions ),\n",
       " Blueprint(Nystroem Kernel SVM Classifier - Forest (5x)),\n",
       " Blueprint(Gradient Boosted Trees Classifier with Early Stopping),\n",
       " Blueprint(Keras Residual AutoInt Classifier using Training Schedule (3 Attention Layers with 2 Heads, 2 Layers: 100, 100 Units)),\n",
       " Blueprint(Keras Deep Residual Neural Network Classifier using Training Schedule (2 Layers: 512, 512 Units)),\n",
       " Blueprint(Stochastic Gradient Descent Classifier),\n",
       " Blueprint(Vowpal Wabbit Stagewise Polynomial Classifier),\n",
       " Blueprint(Balanced RandomForest Classifier (Entropy)),\n",
       " Blueprint(Double Median Absolute Deviation Anomaly Detection),\n",
       " Blueprint(TensorFlow Deep Learning Classifier),\n",
       " Blueprint(Gradient Boosted Trees Classifier with Early Stopping),\n",
       " Blueprint(TensorFlow Deep Learning Classifier),\n",
       " Blueprint(Keras Deep Residual Neural Network Classifier using Training Schedule (3 Layers: 512, 64, 64 Units)),\n",
       " Blueprint(Gradient Boosted Trees Classifier),\n",
       " Blueprint(eXtreme Gradient Boosted Trees Classifier with Early Stopping (learning rate =0.43) (Fast Feature Binning)),\n",
       " Blueprint(eXtreme Gradient Boosted Trees Classifier with Early Stopping (learning rate =0.43) (Fast Feature Binning)),\n",
       " Blueprint(eXtreme Gradient Boosted Trees Classifier with Early Stopping (learning rate =0.01) (Fast Feature Binning)),\n",
       " Blueprint(Elastic-Net Classifier (L2 / Binomial Deviance)),\n",
       " Blueprint(Auto-Tuned Word N-Gram Text Modeler using token occurrences - last_5_size),\n",
       " Blueprint(Mahalanobis Distance Ranked Anomaly Detection with PCA),\n",
       " Blueprint(Balanced RandomForest Classifier (Entropy)),\n",
       " Blueprint(Keras Deep Self-Normalizing Residual Neural Network Classifier using Training Schedule (3 Layers: 256, 128, 64 Units)),\n",
       " Blueprint(Keras Wide Residual Neural Network Classifier using Training Schedule (1 Layer: 1536 Units)),\n",
       " Blueprint(Generalized Additive2 Model),\n",
       " Blueprint(Logistic Regression),\n",
       " Blueprint(RandomForest Classifier (Gini)),\n",
       " Blueprint(LightGBM Random Forest Classifier),\n",
       " Blueprint(Majority Class Classifier),\n",
       " Blueprint(Elastic-Net Classifier (L2 / Binomial Deviance)),\n",
       " Blueprint(Keras Slim Residual Neural Network Classifier using Training Schedule (1 Layer: 64 Units)),\n",
       " Blueprint(Vowpal Wabbit Low Rank Quadratic Classifier),\n",
       " Blueprint(Elastic-Net Classifier (mixing alpha=0.5 / Binomial Deviance)),\n",
       " Blueprint(Keras Slim Residual Neural Network Classifier using Training Schedule (1 Layer: 64 Units)),\n",
       " Blueprint(eXtreme Gradient Boosted Trees Classifier with Early Stopping (learning rate =0.17)),\n",
       " Blueprint(Keras Residual Cross Network Classifier using Training Schedule (3 Cross Layers, 4 Layers: 100, 100, 100, 100 Units)),\n",
       " Blueprint(Elastic-Net Classifier (L2 / Binomial Deviance)),\n",
       " Blueprint(Elastic-Net Classifier (L2 / Binomial Deviance)),\n",
       " Blueprint(Keras Slim Residual Neural Network Classifier using Adaptive Training Schedule (1 Layer: 64 Units)),\n",
       " Blueprint(Keras Neural Network Classifier with Neural Architecture Search (64 Models)),\n",
       " Blueprint(Light Gradient Boosted Trees Classifier with Early Stopping),\n",
       " Blueprint(RandomForest Classifier (Gini)),\n",
       " Blueprint(Dropout Additive Regression Trees Classifier  (15 leaves)),\n",
       " Blueprint(eXtreme Gradient Boosted Trees Classifier with Early Stopping (learning rate =0.01) (Fast Feature Binning)),\n",
       " Blueprint(eXtreme Gradient Boosted Trees Classifier with Early Stopping (learning rate =0.17)),\n",
       " Blueprint(Balanced RandomForest Classifier (Entropy)),\n",
       " Blueprint(Vowpal Wabbit Classifier),\n",
       " Blueprint(Keras Residual Neural Factorization Machine Classifier using Training Schedule (2 Layers: 100, 100 Units)),\n",
       " Blueprint(Elastic-Net Classifier (L2 / Binomial Deviance)),\n",
       " Blueprint(eXtreme Gradient Boosted Trees Classifier with Early Stopping (learning rate =0.43) (Fast Feature Binning) - Forest (10x)),\n",
       " Blueprint(Elastic-Net Classifier (L1 / Binomial Deviance)),\n",
       " Blueprint(Decision Tree Classifier (Gini)),\n",
       " Blueprint(Elastic-Net Classifier (mixing alpha=0.5 / Binomial Deviance))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj.get_blueprints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Blueprint(Keras Residual AutoInt Classifier using Training Schedule (3 Attention Layers with 2 Heads, 2 Layers: 100, 100 Units)),\n",
       " Blueprint(Keras Residual Cross Network Classifier using Training Schedule (3 Cross Layers, 4 Layers: 100, 100, 100, 100 Units)),\n",
       " Blueprint(Keras Residual Neural Factorization Machine Classifier using Training Schedule (2 Layers: 100, 100 Units))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menuKeras = [m for m in proj.get_blueprints() if m.model_type.startswith('Keras Residual')]\n",
    "menuKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFM = menuKeras[2]  #my location for the \"Keras Residual Neural Factorization Machine Classifier\"\n",
    "XNtwk = menuKeras[1]  #my location for the \"Keras Residual Cross Network Classifier\"\n",
    "autoInt = menuKeras[0]  #my location for the \"Keras Residual AutoInt Classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "runNFM = proj.train(NFM)\n",
    "runXNtwk = proj.train(XNtwk)\n",
    "runAutoInt = proj.train(autoInt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model('Keras Residual AutoInt Classifier using Training Schedule (3 Attention Layers with 2 Heads, 2 Layers: 100, 100 Units)')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.models.modeljob.wait_for_async_model_creation(project_id = proj.id,model_job_id = runNFM,max_wait = 3600)\n",
    "dr.models.modeljob.wait_for_async_model_creation(project_id = proj.id,model_job_id = runXNtwk,max_wait = 3600)\n",
    "dr.models.modeljob.wait_for_async_model_creation(project_id = proj.id,model_job_id = runAutoInt,max_wait = 3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model('Keras Residual AutoInt Classifier using Training Schedule (3 Attention Layers with 2 Heads, 2 Layers: 100, 100 Units)'),\n",
       " Model('Keras Residual Cross Network Classifier using Training Schedule (3 Cross Layers, 4 Layers: 100, 100, 100, 100 Units)'),\n",
       " Model('Keras Residual Neural Factorization Machine Classifier using Training Schedule (2 Layers: 100, 100 Units)'),\n",
       " Model('Light Gradient Boosted Trees Classifier with Early Stopping'),\n",
       " Model('Light Gradient Boosting on ElasticNet Predictions '),\n",
       " Model('Light Gradient Boosting on ElasticNet Predictions '),\n",
       " Model('Light Gradient Boosted Trees Classifier with Early Stopping'),\n",
       " Model('Decision Tree Classifier (Gini)'),\n",
       " Model('Balanced RandomForest Classifier (Entropy)'),\n",
       " Model('eXtreme Gradient Boosted Trees Classifier with Early Stopping (learning rate =0.43) (Fast Feature Binning)'),\n",
       " Model('Decision Tree Classifier (Gini)'),\n",
       " Model('Keras Slim Residual Neural Network Classifier using Training Schedule (1 Layer: 64 Units)'),\n",
       " Model('RandomForest Classifier (Gini)'),\n",
       " Model('RandomForest Classifier (Gini)'),\n",
       " Model('Gradient Boosted Trees Classifier'),\n",
       " Model('Nystroem Kernel SVM Classifier - Forest (5x)'),\n",
       " Model('Elastic-Net Classifier (mixing alpha=0.5 / Binomial Deviance)'),\n",
       " Model('Elastic-Net Classifier (mixing alpha=0.5 / Binomial Deviance)'),\n",
       " Model('Elastic-Net Classifier (L2 / Binomial Deviance)'),\n",
       " Model('Elastic-Net Classifier (L2 / Binomial Deviance)'),\n",
       " Model('Vowpal Wabbit Classifier'),\n",
       " Model('Stochastic Gradient Descent Classifier'),\n",
       " Model('Logistic Regression'),\n",
       " Model('Elastic-Net Classifier (L2 / Binomial Deviance)'),\n",
       " Model('Generalized Additive2 Model'),\n",
       " Model('Majority Class Classifier')]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = proj.get_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model('Keras Residual AutoInt Classifier using Training Schedule (3 Attention Layers with 2 Heads, 2 Layers: 100, 100 Units)')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = [m for m in models if ((m.model_type.startswith('Keras Residual AutoInt Classifier')) & (m.sample_pct < cutoff))][0]\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune = model.start_advanced_tuning_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Keras Residual Cross Network Classifier using Training Schedule (3 Cross Layers, 4 Layers: 100, 100, 100, 100 Units)']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune.get_task_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['batch_size',\n",
       " 'cross_network_hidden_bias_initializer',\n",
       " 'cross_network_hidden_initializer',\n",
       " 'cross_network_layers',\n",
       " 'double_batch_size',\n",
       " 'dropout_type',\n",
       " 'early_stopping',\n",
       " 'epochs',\n",
       " 'hidden_activation',\n",
       " 'hidden_batch_norm',\n",
       " 'hidden_bias_initializer',\n",
       " 'hidden_dropout',\n",
       " 'hidden_initializer',\n",
       " 'hidden_l1',\n",
       " 'hidden_l2',\n",
       " 'hidden_units',\n",
       " 'hidden_use_bias',\n",
       " 'learning_rate',\n",
       " 'loss',\n",
       " 'loss_quantile_level',\n",
       " 'max_batch_size',\n",
       " 'max_embedding_size',\n",
       " 'optimizer',\n",
       " 'output_activation',\n",
       " 'output_batch_norm',\n",
       " 'output_bias_initializer',\n",
       " 'output_initializer',\n",
       " 'output_l1',\n",
       " 'output_l2',\n",
       " 'pass_through_inputs',\n",
       " 'prediction_batch_size',\n",
       " 'random_seed',\n",
       " 'stochastic_weight_average_epochs',\n",
       " 'training_schedule_curve',\n",
       " 'training_schedule_cycle_count',\n",
       " 'training_schedule_cycle_scale',\n",
       " 'training_schedule_cycle_warm_up_fraction',\n",
       " 'training_schedule_post_cycle_scale',\n",
       " 'training_schedule_warm_down_fraction',\n",
       " 'use_training_schedule']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_name = 'Keras Residual Cross Network Classifier using Training Schedule (3 Cross Layers, 4 Layers: 100, 100, 100, 100 Units)'\n",
    "tune.get_parameter_names(task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune.set_parameter(task_name=task_name, parameter_name='max_embedding_size', value=32)\n",
    "tune.set_parameter(task_name=task_name, parameter_name='learning_rate', value=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = tune.run()\n",
    "new_model = job.get_result_when_complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Script to loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoIntModel = [m for m in models if ((m.model_type.startswith('Keras Residual AutoInt Classifier')) & (m.sample_pct < cutoff))][0]\n",
    "NFMModel = [m for m in models if ((m.model_type.startswith('Keras Residual Neural Factorization Machine Classifier')) & (m.sample_pct < cutoff))][0]\n",
    "XNtwkModel = [m for m in models if ((m.model_type.startswith('Keras Residual Cross Network Classifier')) & (m.sample_pct < cutoff))][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_tuning(model):\n",
    "    \n",
    "    model_params = model.get_advanced_tuning_parameters()['tuning_parameters']\n",
    "    max_embedding_size = list(filter(lambda param: param['parameter_name'] == 'max_embedding_size', model_params))[0]['default_value']\n",
    "    batch_size = list(filter(lambda param: param['parameter_name'] == 'batch_size', model_params))[0]['default_value']\n",
    "\n",
    "    #All DeepCTR blueprints\n",
    "    max_embedding_sizes = list(map(int,[max_embedding_size,max_embedding_size*2]))\n",
    "    batch_sizes = list(map(int,[batch_size/2,batch_size,batch_size*2]))\n",
    "\n",
    "    #CrossNet only\n",
    "    cross_network_layers = [1,2,3]\n",
    "\n",
    "    #Neural factorization only\n",
    "    biout_dropout = [0.3,0.7]\n",
    "\n",
    "    #AutoInt only\n",
    "    attention_heads = [1,2]\n",
    "    attention_layers = [1,2,3]\n",
    "\n",
    "    #Loop through all relevant tuning parameter combinations\n",
    "    for i in max_embedding_sizes:\n",
    "        for j in batch_sizes:\n",
    "            tune = model.start_advanced_tuning_session()\n",
    "            task_name = tune.get_task_names()[0]\n",
    "            tune.get_parameter_names(task_name)\n",
    "            tune.set_parameter(task_name=task_name, parameter_name='max_embedding_size', value=i)\n",
    "            tune.set_parameter(task_name=task_name, parameter_name='batch_size', value=j)\n",
    "            if task_name.startswith('Keras Residual Cross Network Classifier'):\n",
    "                for k in cross_network_layers:\n",
    "                    tune.set_parameter(task_name=task_name, parameter_name='cross_network_layers', value=k)\n",
    "                    try:\n",
    "                        job = tune.run()\n",
    "                    except:\n",
    "                        pass\n",
    "            if task_name.startswith('Keras Residual AutoInt Classifier'):\n",
    "                for l in attention_heads:\n",
    "                    for m in attention_layers:\n",
    "                        tune.set_parameter(task_name=task_name, parameter_name='attention_heads', value=l)\n",
    "                        tune.set_parameter(task_name=task_name, parameter_name='attention_layers', value=m)\n",
    "                        tune.set_parameter(task_name=task_name, parameter_name='attention_embedding_size', value=i)\n",
    "                        try:\n",
    "                            job = tune.run()\n",
    "                        except:\n",
    "                            pass\n",
    "            if task_name.startswith('Keras Residual Neural Factorization Machine Classifier'):\n",
    "                for o in biout_dropout:\n",
    "                    tune.set_parameter(task_name=task_name, parameter_name='biout_dropout', value=o)\n",
    "                    try:\n",
    "                        job = tune.run()\n",
    "                    except:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_tuning(model=autoIntModel)\n",
    "keras_tuning(model=NFMModel)\n",
    "keras_tuning(model=XNtwkModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After optimizing, re-train on 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj.unlock_holdout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "runBestOn100Pct = proj.get_models()[0].train(sample_pct=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring & looking at accuracy of best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-810eaaca2e27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelRecommendation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRECOMMENDED_MODEL_TYPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRECOMMENDED_FOR_DEPLOYMENT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_model'"
     ]
    }
   ],
   "source": [
    "model = dr.ModelRecommendation.get(proj.id, dr.enums.RECOMMENDED_MODEL_TYPE.RECOMMENDED_FOR_DEPLOYMENT).get_model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model('Keras Residual AutoInt Classifier using Training Schedule (3 Attention Layers with 2 Heads, 2 Layers: 100, 100 Units)')"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = [m for m in models if ((m.model_type.startswith('Keras Residual AutoInt Classifier')) & (m.sample_pct < cutoff))][0]\n",
    "#model = [m for m in models if ((m.model_type.startswith('Keras Residual Cross Network Classifier')) & (m.sample_pct < cutoff))][0]\n",
    "#model = [m for m in models if ((m.model_type.startswith('Keras Residual Neural Factorization Machine Classifier')) & (m.sample_pct < cutoff))][0]\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the threshold - for this use case you might want this lower to maximise recall/sensitivity, i.e less False Negatives\n",
    "#### You may also want to play around with the Profit Curves in the GUI application to optimize choice of threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload scoring dataset and perform scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>line_number</th>\n",
       "      <th>brand</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>category</th>\n",
       "      <th>category_group</th>\n",
       "      <th>size</th>\n",
       "      <th>response</th>\n",
       "      <th>prev_line_number_L1.0</th>\n",
       "      <th>prev_line_number_L2.0</th>\n",
       "      <th>...</th>\n",
       "      <th>prev_size_L2.0</th>\n",
       "      <th>prev_size_L3.0</th>\n",
       "      <th>prev_size_L4.0</th>\n",
       "      <th>prev_size_L5.0</th>\n",
       "      <th>prediction_threshold</th>\n",
       "      <th>prediction</th>\n",
       "      <th>row_id</th>\n",
       "      <th>positive_probability</th>\n",
       "      <th>class_0.0</th>\n",
       "      <th>class_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002fa30f5df73cef97102d1e2890ac</td>\n",
       "      <td>NJUHF</td>\n",
       "      <td>Girls On Film Curve</td>\n",
       "      <td>womens_dresses</td>\n",
       "      <td>dresses</td>\n",
       "      <td>dresses</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111004</td>\n",
       "      <td>0.888996</td>\n",
       "      <td>0.111004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002fa30f5df73cef97102d1e2890ac</td>\n",
       "      <td>NJUHF</td>\n",
       "      <td>Girls On Film Curve</td>\n",
       "      <td>womens_dresses</td>\n",
       "      <td>dresses</td>\n",
       "      <td>dresses</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.194423</td>\n",
       "      <td>0.805577</td>\n",
       "      <td>0.194423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00002fa30f5df73cef97102d1e2890ac</td>\n",
       "      <td>NJUHF</td>\n",
       "      <td>Girls On Film Curve</td>\n",
       "      <td>womens_dresses</td>\n",
       "      <td>dresses</td>\n",
       "      <td>dresses</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.251833</td>\n",
       "      <td>0.748167</td>\n",
       "      <td>0.251833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00002fa30f5df73cef97102d1e2890ac</td>\n",
       "      <td>NJUHF</td>\n",
       "      <td>Girls On Film Curve</td>\n",
       "      <td>womens_dresses</td>\n",
       "      <td>dresses</td>\n",
       "      <td>dresses</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.070352</td>\n",
       "      <td>0.929648</td>\n",
       "      <td>0.070352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00002fa30f5df73cef97102d1e2890ac</td>\n",
       "      <td>NJUHF</td>\n",
       "      <td>Girls On Film Curve</td>\n",
       "      <td>womens_dresses</td>\n",
       "      <td>dresses</td>\n",
       "      <td>dresses</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037421</td>\n",
       "      <td>0.962579</td>\n",
       "      <td>0.037421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            cust_id line_number                brand  \\\n",
       "0  00002fa30f5df73cef97102d1e2890ac       NJUHF  Girls On Film Curve   \n",
       "1  00002fa30f5df73cef97102d1e2890ac       NJUHF  Girls On Film Curve   \n",
       "2  00002fa30f5df73cef97102d1e2890ac       NJUHF  Girls On Film Curve   \n",
       "3  00002fa30f5df73cef97102d1e2890ac       NJUHF  Girls On Film Curve   \n",
       "4  00002fa30f5df73cef97102d1e2890ac       NJUHF  Girls On Film Curve   \n",
       "\n",
       "     sub_category category category_group size  response  \\\n",
       "0  womens_dresses  dresses        dresses   18         0   \n",
       "1  womens_dresses  dresses        dresses   20         0   \n",
       "2  womens_dresses  dresses        dresses   22         0   \n",
       "3  womens_dresses  dresses        dresses   24         0   \n",
       "4  womens_dresses  dresses        dresses   26         1   \n",
       "\n",
       "  prev_line_number_L1.0 prev_line_number_L2.0  ... prev_size_L2.0  \\\n",
       "0                   NaN                   NaN  ...            NaN   \n",
       "1                   NaN                   NaN  ...            NaN   \n",
       "2                   NaN                   NaN  ...            NaN   \n",
       "3                   NaN                   NaN  ...            NaN   \n",
       "4                   NaN                   NaN  ...            NaN   \n",
       "\n",
       "  prev_size_L3.0 prev_size_L4.0 prev_size_L5.0 prediction_threshold  \\\n",
       "0            NaN            NaN            NaN                  0.5   \n",
       "1            NaN            NaN            NaN                  0.5   \n",
       "2            NaN            NaN            NaN                  0.5   \n",
       "3            NaN            NaN            NaN                  0.5   \n",
       "4            NaN            NaN            NaN                  0.5   \n",
       "\n",
       "  prediction row_id positive_probability  class_0.0  class_1.0  \n",
       "0        0.0      0             0.111004   0.888996   0.111004  \n",
       "1        0.0      1             0.194423   0.805577   0.194423  \n",
       "2        0.0      2             0.251833   0.748167   0.251833  \n",
       "3        0.0      3             0.070352   0.929648   0.070352  \n",
       "4        0.0      4             0.037421   0.962579   0.037421  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = proj.upload_dataset(score,max_wait=3600) #send code so you only do it once\n",
    "pred_job = model.request_predictions(dataset.id)\n",
    "preds = pred_job.get_result_when_complete(max_wait=3600)\n",
    "predsAll = pd.concat([score, preds], axis=1)\n",
    "predsAll.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up dataset and aggregate up so it is one row per CUST_ID x ITEM_NUMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>line_number</th>\n",
       "      <th>brand</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>category</th>\n",
       "      <th>category_group</th>\n",
       "      <th>size</th>\n",
       "      <th>response</th>\n",
       "      <th>prev_line_number_L1.0</th>\n",
       "      <th>prev_line_number_L2.0</th>\n",
       "      <th>...</th>\n",
       "      <th>prev_size_L2.0</th>\n",
       "      <th>prev_size_L3.0</th>\n",
       "      <th>prev_size_L4.0</th>\n",
       "      <th>prev_size_L5.0</th>\n",
       "      <th>prediction_threshold</th>\n",
       "      <th>prediction</th>\n",
       "      <th>row_id</th>\n",
       "      <th>positive_probability</th>\n",
       "      <th>class_0.0</th>\n",
       "      <th>class_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002fa30f5df73cef97102d1e2890ac</td>\n",
       "      <td>NJUHF</td>\n",
       "      <td>Girls On Film Curve</td>\n",
       "      <td>womens_dresses</td>\n",
       "      <td>dresses</td>\n",
       "      <td>dresses</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.251833</td>\n",
       "      <td>0.748167</td>\n",
       "      <td>0.251833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000adadd13c7c655c9e08ef17d22446</td>\n",
       "      <td>N6J7W</td>\n",
       "      <td>Monsoon</td>\n",
       "      <td>womens_dresses</td>\n",
       "      <td>dresses</td>\n",
       "      <td>dresses</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.325359</td>\n",
       "      <td>0.674641</td>\n",
       "      <td>0.325359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000190e87f24c447cd20056f7a5f022d</td>\n",
       "      <td>LWPHK</td>\n",
       "      <td>adidas Originals</td>\n",
       "      <td>womens_everyday_sports_tights</td>\n",
       "      <td>trousers</td>\n",
       "      <td>bottoms</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.290460</td>\n",
       "      <td>0.709540</td>\n",
       "      <td>0.290460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001ca92bcd0a45aed94b61338c2bb0d</td>\n",
       "      <td>NR7NH</td>\n",
       "      <td>V by Very Curve</td>\n",
       "      <td>womens_skirts</td>\n",
       "      <td>skirts</td>\n",
       "      <td>bottoms</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>NHLM3</td>\n",
       "      <td>NHLKY</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.541131</td>\n",
       "      <td>0.458869</td>\n",
       "      <td>0.541131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001ff128d96a4af204bf62e81ac342b</td>\n",
       "      <td>NUCP4</td>\n",
       "      <td>V by Very</td>\n",
       "      <td>womens_basics_leggings</td>\n",
       "      <td>trousers</td>\n",
       "      <td>bottoms</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.194114</td>\n",
       "      <td>0.805886</td>\n",
       "      <td>0.194114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            cust_id line_number                brand  \\\n",
       "0  00002fa30f5df73cef97102d1e2890ac       NJUHF  Girls On Film Curve   \n",
       "1  0000adadd13c7c655c9e08ef17d22446       N6J7W              Monsoon   \n",
       "2  000190e87f24c447cd20056f7a5f022d       LWPHK     adidas Originals   \n",
       "3  0001ca92bcd0a45aed94b61338c2bb0d       NR7NH      V by Very Curve   \n",
       "4  0001ff128d96a4af204bf62e81ac342b       NUCP4            V by Very   \n",
       "\n",
       "                    sub_category  category category_group size  response  \\\n",
       "0                 womens_dresses   dresses        dresses   22         0   \n",
       "1                 womens_dresses   dresses        dresses   14         0   \n",
       "2  womens_everyday_sports_tights  trousers        bottoms   10         0   \n",
       "3                  womens_skirts    skirts        bottoms   18         1   \n",
       "4         womens_basics_leggings  trousers        bottoms   12         0   \n",
       "\n",
       "  prev_line_number_L1.0 prev_line_number_L2.0  ... prev_size_L2.0  \\\n",
       "0                   NaN                   NaN  ...            NaN   \n",
       "1                   NaN                   NaN  ...            NaN   \n",
       "2                   NaN                   NaN  ...            NaN   \n",
       "3                 NHLM3                 NHLKY  ...             18   \n",
       "4                   NaN                   NaN  ...            NaN   \n",
       "\n",
       "  prev_size_L3.0 prev_size_L4.0 prev_size_L5.0 prediction_threshold  \\\n",
       "0            NaN            NaN            NaN                  0.5   \n",
       "1            NaN            NaN            NaN                  0.5   \n",
       "2            NaN            NaN            NaN                  0.5   \n",
       "3            NaN            NaN            NaN                  0.5   \n",
       "4            NaN            NaN            NaN                  0.5   \n",
       "\n",
       "  prediction row_id positive_probability  class_0.0  class_1.0  \n",
       "0        0.0      2             0.251833   0.748167   0.251833  \n",
       "1        0.0      7             0.325359   0.674641   0.325359  \n",
       "2        0.0     13             0.290460   0.709540   0.290460  \n",
       "3        1.0     24             0.541131   0.458869   0.541131  \n",
       "4        0.0     31             0.194114   0.805886   0.194114  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoredf = predsAll[(predsAll[\"cust_id\"].notnull()) & (predsAll[\"line_number\"].notnull()) & (predsAll[\"response\"].notnull()) & (predsAll[\"prediction\"].notnull())]\n",
    "scoredf = scoredf.sort_values(by=[\"cust_id\",\"line_number\",\"positive_probability\"],ascending=[False,False,False])\n",
    "scoredf = scoredf.groupby([\"cust_id\",\"line_number\"]).first().reset_index()\n",
    "scoredf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy = 0.49521883458454624\n"
     ]
    }
   ],
   "source": [
    "# AutoInt = 48%, XNtwk = x%, NFM = x%\n",
    "print(\"Total accuracy = \"+str(sum(scoredf[\"response\"])/len(scoredf[\"response\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsAll[(predsAll[\"cust_id\"] == \"00000419c5c8eebdb9c91c827a18ea4f\") & (predsAll[\"line_number\"] == \"MXLVF\")]\\\n",
    "                .sort_values(by=[\"cust_id\",\"line_number\",\"positive_probability\"],ascending=[False,False,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>line_number</th>\n",
       "      <th>brand</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>category</th>\n",
       "      <th>category_group</th>\n",
       "      <th>size</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MTAMG</td>\n",
       "      <td>V by Very Curve</td>\n",
       "      <td>womens_jeans</td>\n",
       "      <td>jeans</td>\n",
       "      <td>bottoms</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MTAMG</td>\n",
       "      <td>V by Very Curve</td>\n",
       "      <td>womens_jeans</td>\n",
       "      <td>jeans</td>\n",
       "      <td>bottoms</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MTAMG</td>\n",
       "      <td>V by Very Curve</td>\n",
       "      <td>womens_jeans</td>\n",
       "      <td>jeans</td>\n",
       "      <td>bottoms</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MTAMG</td>\n",
       "      <td>V by Very Curve</td>\n",
       "      <td>womens_jeans</td>\n",
       "      <td>jeans</td>\n",
       "      <td>bottoms</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MTAMG</td>\n",
       "      <td>V by Very Curve</td>\n",
       "      <td>womens_jeans</td>\n",
       "      <td>jeans</td>\n",
       "      <td>bottoms</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MTAMG</td>\n",
       "      <td>V by Very Curve</td>\n",
       "      <td>womens_jeans</td>\n",
       "      <td>jeans</td>\n",
       "      <td>bottoms</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MTAMG</td>\n",
       "      <td>V by Very Curve</td>\n",
       "      <td>womens_jeans</td>\n",
       "      <td>jeans</td>\n",
       "      <td>bottoms</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MXLVF</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>40D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MXLVF</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>40DD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MXLVF</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>40E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MXLVF</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>40F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MXLVF</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>40FF</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MXLVF</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>40G</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MXLVF</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>40GG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MXLVF</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>40H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MXLVF</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>40HH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MXLVF</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>42D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MXLVF</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>42DD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MXLVF</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>42E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MXLVF</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>42F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MXLVF</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>42FF</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MXLVF</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>42G</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MXLVF</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>42GG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MXLVF</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>42H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MXLVF</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>44D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MXLVF</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>44DD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MXLVF</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>44E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MXLVF</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>44F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MXLVF</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>44FF</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MXLVF</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>44G</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>MXLVF</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>44GG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>N6NVX</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>38C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>N6NVX</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>38D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>N6NVX</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>38DD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>N6NVX</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>38E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>N6NVX</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>38F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>N6NVX</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>38FF</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>N6NVX</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>38G</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>N6NVX</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>40C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>N6NVX</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>40D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>N6NVX</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>40DD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>N6NVX</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>40E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>N6NVX</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>40F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>00000419c5c8eebdb9c91c827a18ea4f</td>\n",
       "      <td>N6NVX</td>\n",
       "      <td>Pour Moi</td>\n",
       "      <td>womens_lingerie_bras_matching_sets</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>lingerie</td>\n",
       "      <td>40FF</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             cust_id line_number            brand  \\\n",
       "0   00000419c5c8eebdb9c91c827a18ea4f       MTAMG  V by Very Curve   \n",
       "1   00000419c5c8eebdb9c91c827a18ea4f       MTAMG  V by Very Curve   \n",
       "2   00000419c5c8eebdb9c91c827a18ea4f       MTAMG  V by Very Curve   \n",
       "3   00000419c5c8eebdb9c91c827a18ea4f       MTAMG  V by Very Curve   \n",
       "4   00000419c5c8eebdb9c91c827a18ea4f       MTAMG  V by Very Curve   \n",
       "5   00000419c5c8eebdb9c91c827a18ea4f       MTAMG  V by Very Curve   \n",
       "6   00000419c5c8eebdb9c91c827a18ea4f       MTAMG  V by Very Curve   \n",
       "7   00000419c5c8eebdb9c91c827a18ea4f       MXLVF         Pour Moi   \n",
       "8   00000419c5c8eebdb9c91c827a18ea4f       MXLVF         Pour Moi   \n",
       "9   00000419c5c8eebdb9c91c827a18ea4f       MXLVF         Pour Moi   \n",
       "10  00000419c5c8eebdb9c91c827a18ea4f       MXLVF         Pour Moi   \n",
       "11  00000419c5c8eebdb9c91c827a18ea4f       MXLVF         Pour Moi   \n",
       "12  00000419c5c8eebdb9c91c827a18ea4f       MXLVF         Pour Moi   \n",
       "13  00000419c5c8eebdb9c91c827a18ea4f       MXLVF         Pour Moi   \n",
       "14  00000419c5c8eebdb9c91c827a18ea4f       MXLVF         Pour Moi   \n",
       "15  00000419c5c8eebdb9c91c827a18ea4f       MXLVF         Pour Moi   \n",
       "16  00000419c5c8eebdb9c91c827a18ea4f       MXLVF         Pour Moi   \n",
       "17  00000419c5c8eebdb9c91c827a18ea4f       MXLVF         Pour Moi   \n",
       "18  00000419c5c8eebdb9c91c827a18ea4f       MXLVF         Pour Moi   \n",
       "19  00000419c5c8eebdb9c91c827a18ea4f       MXLVF         Pour Moi   \n",
       "20  00000419c5c8eebdb9c91c827a18ea4f       MXLVF         Pour Moi   \n",
       "21  00000419c5c8eebdb9c91c827a18ea4f       MXLVF         Pour Moi   \n",
       "22  00000419c5c8eebdb9c91c827a18ea4f       MXLVF         Pour Moi   \n",
       "23  00000419c5c8eebdb9c91c827a18ea4f       MXLVF         Pour Moi   \n",
       "24  00000419c5c8eebdb9c91c827a18ea4f       MXLVF         Pour Moi   \n",
       "25  00000419c5c8eebdb9c91c827a18ea4f       MXLVF         Pour Moi   \n",
       "26  00000419c5c8eebdb9c91c827a18ea4f       MXLVF         Pour Moi   \n",
       "27  00000419c5c8eebdb9c91c827a18ea4f       MXLVF         Pour Moi   \n",
       "28  00000419c5c8eebdb9c91c827a18ea4f       MXLVF         Pour Moi   \n",
       "29  00000419c5c8eebdb9c91c827a18ea4f       MXLVF         Pour Moi   \n",
       "30  00000419c5c8eebdb9c91c827a18ea4f       MXLVF         Pour Moi   \n",
       "31  00000419c5c8eebdb9c91c827a18ea4f       N6NVX         Pour Moi   \n",
       "32  00000419c5c8eebdb9c91c827a18ea4f       N6NVX         Pour Moi   \n",
       "33  00000419c5c8eebdb9c91c827a18ea4f       N6NVX         Pour Moi   \n",
       "34  00000419c5c8eebdb9c91c827a18ea4f       N6NVX         Pour Moi   \n",
       "35  00000419c5c8eebdb9c91c827a18ea4f       N6NVX         Pour Moi   \n",
       "36  00000419c5c8eebdb9c91c827a18ea4f       N6NVX         Pour Moi   \n",
       "37  00000419c5c8eebdb9c91c827a18ea4f       N6NVX         Pour Moi   \n",
       "38  00000419c5c8eebdb9c91c827a18ea4f       N6NVX         Pour Moi   \n",
       "39  00000419c5c8eebdb9c91c827a18ea4f       N6NVX         Pour Moi   \n",
       "40  00000419c5c8eebdb9c91c827a18ea4f       N6NVX         Pour Moi   \n",
       "41  00000419c5c8eebdb9c91c827a18ea4f       N6NVX         Pour Moi   \n",
       "42  00000419c5c8eebdb9c91c827a18ea4f       N6NVX         Pour Moi   \n",
       "43  00000419c5c8eebdb9c91c827a18ea4f       N6NVX         Pour Moi   \n",
       "\n",
       "                          sub_category  category category_group  size  \\\n",
       "0                         womens_jeans     jeans        bottoms    16   \n",
       "1                         womens_jeans     jeans        bottoms    18   \n",
       "2                         womens_jeans     jeans        bottoms    20   \n",
       "3                         womens_jeans     jeans        bottoms    22   \n",
       "4                         womens_jeans     jeans        bottoms    24   \n",
       "5                         womens_jeans     jeans        bottoms    26   \n",
       "6                         womens_jeans     jeans        bottoms    28   \n",
       "7   womens_lingerie_bras_matching_sets  lingerie       lingerie   40D   \n",
       "8   womens_lingerie_bras_matching_sets  lingerie       lingerie  40DD   \n",
       "9   womens_lingerie_bras_matching_sets  lingerie       lingerie   40E   \n",
       "10  womens_lingerie_bras_matching_sets  lingerie       lingerie   40F   \n",
       "11  womens_lingerie_bras_matching_sets  lingerie       lingerie  40FF   \n",
       "12  womens_lingerie_bras_matching_sets  lingerie       lingerie   40G   \n",
       "13  womens_lingerie_bras_matching_sets  lingerie       lingerie  40GG   \n",
       "14  womens_lingerie_bras_matching_sets  lingerie       lingerie   40H   \n",
       "15  womens_lingerie_bras_matching_sets  lingerie       lingerie  40HH   \n",
       "16  womens_lingerie_bras_matching_sets  lingerie       lingerie   42D   \n",
       "17  womens_lingerie_bras_matching_sets  lingerie       lingerie  42DD   \n",
       "18  womens_lingerie_bras_matching_sets  lingerie       lingerie   42E   \n",
       "19  womens_lingerie_bras_matching_sets  lingerie       lingerie   42F   \n",
       "20  womens_lingerie_bras_matching_sets  lingerie       lingerie  42FF   \n",
       "21  womens_lingerie_bras_matching_sets  lingerie       lingerie   42G   \n",
       "22  womens_lingerie_bras_matching_sets  lingerie       lingerie  42GG   \n",
       "23  womens_lingerie_bras_matching_sets  lingerie       lingerie   42H   \n",
       "24  womens_lingerie_bras_matching_sets  lingerie       lingerie   44D   \n",
       "25  womens_lingerie_bras_matching_sets  lingerie       lingerie  44DD   \n",
       "26  womens_lingerie_bras_matching_sets  lingerie       lingerie   44E   \n",
       "27  womens_lingerie_bras_matching_sets  lingerie       lingerie   44F   \n",
       "28  womens_lingerie_bras_matching_sets  lingerie       lingerie  44FF   \n",
       "29  womens_lingerie_bras_matching_sets  lingerie       lingerie   44G   \n",
       "30  womens_lingerie_bras_matching_sets  lingerie       lingerie  44GG   \n",
       "31  womens_lingerie_bras_matching_sets  lingerie       lingerie   38C   \n",
       "32  womens_lingerie_bras_matching_sets  lingerie       lingerie   38D   \n",
       "33  womens_lingerie_bras_matching_sets  lingerie       lingerie  38DD   \n",
       "34  womens_lingerie_bras_matching_sets  lingerie       lingerie   38E   \n",
       "35  womens_lingerie_bras_matching_sets  lingerie       lingerie   38F   \n",
       "36  womens_lingerie_bras_matching_sets  lingerie       lingerie  38FF   \n",
       "37  womens_lingerie_bras_matching_sets  lingerie       lingerie   38G   \n",
       "38  womens_lingerie_bras_matching_sets  lingerie       lingerie   40C   \n",
       "39  womens_lingerie_bras_matching_sets  lingerie       lingerie   40D   \n",
       "40  womens_lingerie_bras_matching_sets  lingerie       lingerie  40DD   \n",
       "41  womens_lingerie_bras_matching_sets  lingerie       lingerie   40E   \n",
       "42  womens_lingerie_bras_matching_sets  lingerie       lingerie   40F   \n",
       "43  womens_lingerie_bras_matching_sets  lingerie       lingerie  40FF   \n",
       "\n",
       "    response  \n",
       "0          0  \n",
       "1          1  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "5          0  \n",
       "6          0  \n",
       "7          0  \n",
       "8          0  \n",
       "9          0  \n",
       "10         0  \n",
       "11         0  \n",
       "12         0  \n",
       "13         0  \n",
       "14         0  \n",
       "15         0  \n",
       "16         0  \n",
       "17         1  \n",
       "18         0  \n",
       "19         0  \n",
       "20         0  \n",
       "21         0  \n",
       "22         0  \n",
       "23         0  \n",
       "24         0  \n",
       "25         0  \n",
       "26         0  \n",
       "27         0  \n",
       "28         0  \n",
       "29         0  \n",
       "30         0  \n",
       "31         0  \n",
       "32         0  \n",
       "33         0  \n",
       "34         0  \n",
       "35         0  \n",
       "36         0  \n",
       "37         0  \n",
       "38         0  \n",
       "39         0  \n",
       "40         1  \n",
       "41         0  \n",
       "42         0  \n",
       "43         0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsAll[(predsAll[\"cust_id\"] == \"00000419c5c8eebdb9c91c827a18ea4f\")] # & (predsAll[\"category_group\"] == \"lingerie\")]\n",
    "df[(df[\"cust_id\"] == \"00000419c5c8eebdb9c91c827a18ea4f\")]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
