{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23697938",
   "metadata": {},
   "source": [
    "## Deployment - Batch prediction examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "204b9c72",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mmax_colwidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_colwidth=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aa6bdce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datarobot.rest.RESTClientObject at 0x7fbcd3f10ac0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display\n",
    "import datarobot as dr\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "import io\n",
    "import requests\n",
    "import json\n",
    "from pprint import pprint as pp\n",
    "\n",
    "USERNAME = os.environ['DATAROBOT_USERNAME']\n",
    "API_KEY = os.environ['DATAROBOT_API_TOKEN']\n",
    "DATAROBOT_KEY = os.environ['DATAROBOT_KEY']\n",
    "HOSTNAME = 'https://app.datarobot.com/' # The host to use for the REST API\n",
    "ENDPOINT = HOSTNAME + 'api/v2/' # The host to use for the REST API\n",
    "\n",
    "dr.Client(token=API_KEY, endpoint=ENDPOINT)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a167aeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term\n",
      "int_rate\n",
      "grade\n",
      "sub_grade\n",
      "emp_title\n",
      "emp_length\n",
      "home_ownership\n",
      "verification_status\n",
      "pymnt_plan\n",
      "url\n",
      "desc\n",
      "purpose\n",
      "title\n",
      "zip_code\n",
      "addr_state\n",
      "earliest_cr_line\n",
      "initial_list_status\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot use .str.encode with values of inferred dtype 'bytes'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(column)\n\u001b[1;32m     14\u001b[0m     df_pred_full[column] \u001b[38;5;241m=\u001b[39m df_pred_full[column]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m df_pred_full[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_pred_full\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m                                    \u001b[38;5;66;03m# that can be passed in to BatchPredictionJob.score\u001b[39;00m\n\u001b[1;32m     19\u001b[0m df_pred_subset \u001b[38;5;241m=\u001b[39m df_pred[:\u001b[38;5;241m180\u001b[39m]  \u001b[38;5;66;03m#pd.read_csv(pred_file)[:13]\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/strings/accessor.py:115\u001b[0m, in \u001b[0;36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[1;32m    111\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use .str.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with values of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferred dtype \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m     )\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot use .str.encode with values of inferred dtype 'bytes'."
     ]
    }
   ],
   "source": [
    "#\n",
    "# Get the dataset for predictions\n",
    "#\n",
    "pred_file = './data/DR_Demo_10K_Lending_Club_Loans_pred.csv'\n",
    "df_pred_full = pd.read_csv(pred_file)   # there may be a limit to the number of rows \n",
    "\n",
    "# Encode all str columns as utf8\n",
    "str_cols = df_pred_full.select_dtypes(include=['object']).columns\n",
    "str_cols\n",
    "for column in str_cols:\n",
    "#     df[column] = df_peru[column].str.encode('utf-8')\n",
    "#     print(column +' - ' )\n",
    "    print(column)\n",
    "    df_pred_full[column] = df_pred_full[column].str.encode('utf-8')\n",
    "\n",
    "    \n",
    "df_pred_full['desc'] = df_pred_full.desc.str.encode('utf-8')\n",
    "                                   # that can be passed in to BatchPredictionJob.score\n",
    "df_pred_subset = df_pred[:180]  #pd.read_csv(pred_file)[:13]\n",
    "\n",
    "df_pred_fail = df_pred[179:180]\n",
    "\n",
    "df_pred = df_pred_subset\n",
    "df_pred = df_pred_full\n",
    "# df_pred = df_pred_fail\n",
    "\n",
    "print('df_pred.shape:', df_pred.shape)\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1b1bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.dtypes\n",
    "str_cols = df_pred.select_dtypes(include=['object']).columns\n",
    "str_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7dcc77e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term - \n",
      "int_rate - \n",
      "grade - \n",
      "sub_grade - \n",
      "emp_title - \n",
      "emp_length - \n",
      "home_ownership - \n",
      "verification_status - \n",
      "pymnt_plan - \n",
      "url - \n",
      "desc - \n",
      "purpose - \n",
      "title - \n",
      "zip_code - \n",
      "addr_state - \n",
      "earliest_cr_line - \n",
      "initial_list_status - \n"
     ]
    }
   ],
   "source": [
    "str_cols = df_pred.select_dtypes(include=['object']).columns\n",
    "str_cols\n",
    "for column in str_cols:\n",
    "#     df[column] = df_peru[column].str.encode('utf-8')\n",
    "    print(column +' - ' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0b3c1b63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loan_amnt': {179: 20000},\n",
       " 'funded_amnt': {179: 20000},\n",
       " 'term': {179: ' 36 months'},\n",
       " 'int_rate': {179: '14.22%'},\n",
       " 'installment': {179: 685.69},\n",
       " 'grade': {179: 'C'},\n",
       " 'sub_grade': {179: 'C5'},\n",
       " 'emp_title': {179: 'Infinite Solutions'},\n",
       " 'emp_length': {179: '4 years'},\n",
       " 'home_ownership': {179: 'MORTGAGE'},\n",
       " 'annual_inc': {179: 62000.0},\n",
       " 'verification_status': {179: 'not verified'},\n",
       " 'pymnt_plan': {179: 'n'},\n",
       " 'url': {179: 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=490965'},\n",
       " 'desc': {179: b'  Borrower added on 03/11/10 > We will be using the money to pay for our wedding expenses. We will be getting married at the coonamessett Inn in Falmouth, MA. The venue is approximately 16,000 including food of course. The flowers are 2,000, the dress is 1,000, invitations are another 250, photographer is 2500, the Dj was 1,500.the tux was 150, and the jp is 500 that\\xc2\\x92\\xc2\\xa2\\xc3\\x8e\\xc2\\x97\\xc3\\x8e\\xc3\\x88s the break down its aprox a 30,000 wedding but you only do it once and we both have large families but we are doing it ourselves. At 27 it\\xc2\\x92\\xc2\\xa2\\xc3\\x8e\\xc2\\x97\\xc3\\x8e\\xc3\\x88s not a small feat so your help is greatly appreciated and we won\\xc2\\x92\\xc2\\xa2\\xc3\\x8e\\xc2\\x97\\xc3\\x8e\\xc3\\x88t let you down I give u my word.<br/> Borrower added on 03/11/10 > I work in the cell phone industry I build cellar towers and install the equipment. I install all carriers at&t, Verizon, sprint/Nextel, t-mobile, metro pcs.  So my job is very secure they are always upgrading my company just got a 347 site contract for at&t so it will be a very busy couple especially with the new launch of 4g.<br/> Borrower added on 03/11/10 > My fianc\\xc2\\x92\\xc3\\x9b\\xc3\\x8e\\xc2\\xa9e will also be paying the loan she is a CPA.<br/>'},\n",
       " 'purpose': {179: 'wedding'},\n",
       " 'title': {179: 'Wedding'},\n",
       " 'zip_code': {179: '023xx'},\n",
       " 'addr_state': {179: 'MA'},\n",
       " 'dti': {179: 11.52},\n",
       " 'delinq_2yrs': {179: 0.0},\n",
       " 'earliest_cr_line': {179: '8/1/01'},\n",
       " 'inq_last_6mths': {179: 0.0},\n",
       " 'mths_since_last_delinq': {179: 50.0},\n",
       " 'mths_since_last_record': {179: nan},\n",
       " 'open_acc': {179: 8.0},\n",
       " 'pub_rec': {179: 0.0},\n",
       " 'revol_bal': {179: 21116},\n",
       " 'revol_util': {179: 66.8},\n",
       " 'total_acc': {179: 16.0},\n",
       " 'initial_list_status': {179: 'f'},\n",
       " 'mths_since_last_major_derog': {179: nan},\n",
       " 'policy_code': {179: 1}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_fail.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4321c7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5f6e3af7684b9709659b5dce\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Get the most recent lending club deployment\n",
    "#\n",
    "\n",
    "# Get deployments by search string\n",
    "deployments_lc = dr.Deployment.list(search='is_bad Predictions')\n",
    "deployments_lc\n",
    "\n",
    "deployment = deployments_lc[-1]\n",
    "print(deployment.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9d14dd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'build_environment_type': 'DataRobot',\n",
      " 'deployed_at': '2020-09-25T18:46:15.629000Z',\n",
      " 'id': '5f64f7c8758c297b8c29e3ab',\n",
      " 'project_id': '5f64f3a656f28d076e6723cb',\n",
      " 'project_name': '10K Lending Club Loans.csv',\n",
      " 'target_name': 'is_bad',\n",
      " 'target_type': 'Binary',\n",
      " 'type': 'Light Gradient Boosted Trees Classifier with Early Stopping',\n",
      " 'unstructured_model_kind': False,\n",
      " 'unsupervised_mode': False}\n",
      "\n",
      "project_id: 5f64f3a656f28d076e6723cb\n",
      "model_id: 5f64f7c8758c297b8c29e3ab\n"
     ]
    }
   ],
   "source": [
    "pp(deployment.model)\n",
    "print()\n",
    "\n",
    "project_id = deployment.model.get('project_id')\n",
    "print('project_id:', project_id)\n",
    "\n",
    "model_id = deployment.model.get('id')\n",
    "print('model_id:', model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4d17831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# FYI, the BATCH_PREDICTIONS_URL = 'https://app.datarobot.com/api/v2'\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad848ba2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Batch scoring synchronously (Program flow waits for call to return).  \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# - If output_settings includes a 'file:' element, the call waits for completion before returning program flow.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# With prediction explanations if uncommented as shown. \u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      7\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 8\u001b[0m \u001b[43mdr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBatchPredictionJob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeployment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintake_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocalFile\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfile\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/DR_Demo_10K_Lending_Club_Loans_pred.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Path or Pandas or file-like object.  \u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[38;5;66;43;03m# Such as: 'file': df_pred_data\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocalFile\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutputfile.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If explanations are required, uncomment the line below\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# max_explanations=3,\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Uncomment this for Prediction Warnings, if enabled for your deployment.\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# prediction_warning_enabled=True\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m- Execution time: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m min\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m ((time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m))\n\u001b[1;32m     27\u001b[0m df_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./outputfile.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/datarobot/models/batch_prediction_job.py:707\u001b[0m, in \u001b[0;36mBatchPredictionJob.score\u001b[0;34m(cls, deployment, intake_settings, output_settings, csv_settings, timeseries_settings, num_concurrent, chunk_size, passthrough_columns, passthrough_columns_set, max_explanations, threshold_high, threshold_low, prediction_warning_enabled, include_prediction_status, skip_drift_tracking, prediction_instance, abort_on_error, column_names_remapping, include_probabilities, include_probabilities_classes, download_timeout, download_read_timeout)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m \n\u001b[1;32m    704\u001b[0m     \u001b[38;5;66;03m# We must download the result to `output_file`\u001b[39;00m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;66;03m# And clean up any thread we spawned during uploading\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m         \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_read_timeout\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    711\u001b[0m         output_file\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/datarobot/models/batch_prediction_job.py:1113\u001b[0m, in \u001b[0;36mBatchPredictionJob.download\u001b[0;34m(self, fileobj, timeout, read_timeout)\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload\u001b[39m(\u001b[38;5;28mself\u001b[39m, fileobj, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m120\u001b[39m, read_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m660\u001b[39m):\n\u001b[1;32m   1087\u001b[0m     \u001b[38;5;124;03m\"\"\"Downloads the CSV result of a prediction job\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m \n\u001b[1;32m   1089\u001b[0m \u001b[38;5;124;03m    Attributes\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;124;03m        Seconds to wait for the server to respond between chunks.\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1113\u001b[0m     status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m     download_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1115\u001b[0m         status[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinks\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownload\u001b[39m\u001b[38;5;124m\"\u001b[39m], stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, timeout\u001b[38;5;241m=\u001b[39mread_timeout,\n\u001b[1;32m   1116\u001b[0m     )\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8192\u001b[39m)\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m download_iter:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/datarobot/models/batch_prediction_job.py:1145\u001b[0m, in \u001b[0;36mBatchPredictionJob._wait_for_download\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start \u001b[38;5;241m>\u001b[39m timeout:\n\u001b[1;32m   1143\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1145\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownload\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m status[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinks\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;66;03m# Ignore 404 errors here if the job never started - then we can't abort it\u001b[39;00m\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(ignore_404_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#\n",
    "# Batch scoring synchronously (Program flow waits for call to return).  \n",
    "# - If output_settings includes a 'file:' element, the call waits for completion before returning program flow.\n",
    "#\n",
    "# With prediction explanations if uncommented as shown. \n",
    "#\n",
    "t0 = time.time()\n",
    "dr.BatchPredictionJob.score(\n",
    "    deployment.id,\n",
    "    intake_settings={\n",
    "        'type': 'localFile',\n",
    "        'file': './data/DR_Demo_10K_Lending_Club_Loans_pred.csv' # Path or Pandas or file-like object.  \n",
    "                                                                 # Such as: 'file': df_pred_data\n",
    "    },\n",
    "    output_settings={\n",
    "        'type': 'localFile',\n",
    "        'path': 'outputfile.csv'\n",
    "    },\n",
    "    download_timeout=6000,\n",
    "    # If explanations are required, uncomment the line below\n",
    "    # max_explanations=3,\n",
    "    # Uncomment this for Prediction Warnings, if enabled for your deployment.\n",
    "    # prediction_warning_enabled=True\n",
    ")\n",
    "print('- Execution time: %.3f min' % ((time.time() - t0)/60))\n",
    "\n",
    "df_results = pd.read_csv('./outputfile.csv')\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52cb0a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Batch scoring asynchronously (Program flow waits for call to return).  \n",
    "#\n",
    "\n",
    "# Helper function to check the status of the prediction job\n",
    "def check_job_status(job, sleep=10):\n",
    "    \"\"\"\n",
    "    After a batch prediction request is posted asynchronously, the call retuns a jobid\n",
    "    and program flow returns.  This helper function checks the request processing status and\n",
    "    prints current state\n",
    "    \n",
    "    Parameters:\n",
    "    - job id\n",
    "    - sleep: the time to wait between status checks\n",
    "    \n",
    "    Returns:\n",
    "    - nothing\n",
    "    \"\"\"\n",
    "\n",
    "    out_str = ''\n",
    "    \n",
    "    def output(txt, add_flush=True):       \n",
    "        if add_flush:\n",
    "            print(txt, end='\\r', flush=True)\n",
    "        else:\n",
    "            print(txt)\n",
    "\n",
    "    job_status = job.get_status()\n",
    "\n",
    "    while True: \n",
    "        job_status = job.get_status()\n",
    "        elapsed_time = job_status['elapsed_time_sec']\n",
    "        status = job_status.get('status')\n",
    "        status_details = job_status['status_details']\n",
    "        \n",
    "        out_str = \"Wait time {:.3f} minutes - Status {}. \"  \\\n",
    "                  \"Queue posiition: {} - {}\".format(elapsed_time/60, \n",
    "                                                                                           status,\n",
    "                                                                                           job._safe_data.get('queue_position'),\n",
    "                                                                                           status_details)\n",
    "\n",
    "        if job.get_status().get('status') == 'INITIALIZING':\n",
    "            str_split = status_details.split()\n",
    "            \n",
    "            try:\n",
    "                job_index = str_split.index(\"job(s)\")\n",
    "                num_jobs_ahead = str_split[job_index-1]\n",
    "                status_details = str(num_jobs_ahead+' job(s) ahead')\n",
    "            except Exception as e:\n",
    "                status_details = '0 job(s) ahead'\n",
    "\n",
    "            output(out_str)\n",
    "        else:\n",
    "            print()\n",
    "            output(out_str, add_flush=False)\n",
    "\n",
    "            if job.get_status().get('status') == 'COMPLETED' or \\\n",
    "               job.get_status().get('status') == 'ABORTED':\n",
    "                    break\n",
    "            \n",
    "        time.sleep(sleep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "353d4b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job attributes:\n",
      "{'_completed_resource_url': None,\n",
      " '_safe_data': {'created': '2022-04-20T15:34:57.179000Z',\n",
      "                'created_by': {'full_name': 'Matthew Cohen',\n",
      "                               'user_id': '5a8a6402b11ba422e62b7c7a',\n",
      "                               'username': 'matthew.cohen@datarobot.com'},\n",
      "                'elapsed_time_sec': 1,\n",
      "                'failed_rows': 0,\n",
      "                'id': '626028211b10eba4835a54d4',\n",
      "                'job_spec': {'abort_on_error': True,\n",
      "                             'chunk_size': 'auto',\n",
      "                             'csv_settings': {'delimiter': ',',\n",
      "                                              'encoding': 'utf-8',\n",
      "                                              'quotechar': '\"'},\n",
      "                             'deployment_id': '5f6e3af7684b9709659b5dce',\n",
      "                             'disable_row_level_error_handling': False,\n",
      "                             'include_prediction_status': False,\n",
      "                             'include_probabilities': True,\n",
      "                             'include_probabilities_classes': [],\n",
      "                             'intake_settings': {'type': 'localFile'},\n",
      "                             'max_explanations': 0,\n",
      "                             'num_concurrent': 3,\n",
      "                             'output_settings': {'type': 'localFile'},\n",
      "                             'redacted_fields': [],\n",
      "                             'skip_drift_tracking': False},\n",
      "                'links': {'csv_upload': 'https://app.datarobot.com/api/v2/batchPredictions/626028211b10eba4835a54d4/csvUpload/',\n",
      "                          'self': 'https://app.datarobot.com/api/v2/batchPredictions/626028211b10eba4835a54d4/'},\n",
      "                'logs': ['Job created by matthew.cohen@datarobot.com at '\n",
      "                         '2022-04-20 15:34:57.179000',\n",
      "                         'Submitted job to queue. At the time of submission 1 '\n",
      "                         'job(s) was waiting for processing before this job. '\n",
      "                         'at 2022-04-20 15:34:57.751000'],\n",
      "                'percentage_completed': 0.0,\n",
      "                'queue_position': 1,\n",
      "                'queued': True,\n",
      "                'scored_rows': 0,\n",
      "                'skipped_rows': 0,\n",
      "                'source': 'api_client_python',\n",
      "                'status': 'INITIALIZING',\n",
      "                'status_details': 'Submitted job to queue. At the time of '\n",
      "                                  'submission 1 job(s) was waiting for '\n",
      "                                  'processing before this job. at 2022-04-20 '\n",
      "                                  '15:34:57.751000'},\n",
      " 'id': '626028211b10eba4835a54d4',\n",
      " 'is_blocked': None,\n",
      " 'job_type': 'batchPredictions',\n",
      " 'model': None,\n",
      " 'model_id': None,\n",
      " 'project': Project(None),\n",
      " 'project_id': None,\n",
      " 'status': 'INITIALIZING'}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Batch scoring asynchronously (Program flow returns a job id, poll the job for completion).  \n",
    "#\n",
    "job = dr.BatchPredictionJob.score(\n",
    "    deployment.id,\n",
    "#     prediction_instance={\n",
    "#         'hostName': host.url,\n",
    "#     },\n",
    "    intake_settings={\n",
    "        'type': 'localFile',\n",
    "#         'file': './data/DR_Demo_10K_Lending_Club_Loans_pred.csv',  # pred file as csv\n",
    "        'file': df_pred,  # pred file as dataframe\n",
    "    },\n",
    "    output_settings={\n",
    "        'type': 'localFile',\n",
    "    },\n",
    ")\n",
    "\n",
    "# Print the job object\n",
    "print('job attributes:')\n",
    "pp(job.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486096d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_job_status(job, sleep=3)\n",
    "print()\n",
    "\n",
    "print('Results:')\n",
    "result_bytes = job.get_result_when_complete()\n",
    "result_str = result_bytes.decode(\"utf-8\") \n",
    "result_io = io.StringIO(result_str)\n",
    "# print(result_str)\n",
    "df = pd.read_csv(result_io, sep=\",\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7730be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
