---
title: "DataRobot vs. Open Source Forecasting Tools"
author: "Zachary Deane-Mayer"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    includes:
      in_header: header.tex
#classoption: landscape
---

```{r setup, include=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
rm(list=ls(all=T))
gc(reset=T)
options(xtable.comment = FALSE)
knitr::opts_chunk$set(echo = FALSE)
library(forecast)
library(fpp)
library(data.table)
library(reshape2)
library(readr)
library(pbapply)
library(yaml)
library(parallel)
library(pbapply)
library(yaml)
library(parallel)
library(ggplot2)
library(matrixStats)
library(knitr)
library(kableExtra)
library(xtable)
library(bit64)

normalizedGini <- function(aa, pp) {
  Gini <- function(a, p) {
    if (length(a) !=  length(p)) stop("Actual and Predicted need to be equal lengths!")
    temp.df <- data.frame(actual = a, pred = p, range=c(1:length(a)))
    temp.df <- temp.df[order(-temp.df$pred, temp.df$range),]
    population.delta <- 1 / length(a)
    total.losses <- sum(a)
    null.losses <- rep(population.delta, length(a)) # Hopefully is similar to accumulatedPopulationPercentageSum
    accum.losses <- temp.df$actual / total.losses # Hopefully is similar to accumulatedLossPercentageSum
    gini.sum <- cumsum(accum.losses - null.losses) # Not sure if this is having the same effect or not
    sum(gini.sum) / length(a)
  }
  Gini(aa,pp) / Gini(aa,aa)
}

load(file='~/workspace/data-science-scripts/zach/compare_data.Rdata')

EU_DIR <- '~/workspace/data-science-scripts/zach/eq_preds/'
EU_files <- list.files(EU_DIR)
EU <- rbindlist(lapply(EU_files, function(x){
  #print(x)
  dat <- fread(paste0(EU_DIR, x), header=TRUE)
  P <- as.numeric(dat[[1]])
  A <- as.numeric(dat[['y']])
  N = length(P)
  e <- A - P
  gini <- normalizedGini(A, P)
  if(!is.finite(gini)){
    gini <- 0
  }
  data.table(
    dataset=x,
    `Prediction RMSE` = sqrt(mean(e^2)),
    `Prediction MAD` = median(abs(e)),
    `Prediction Gini Norm` = gini,
    #y_scale = median(abs(- A[])),
    method = 'Eureqa'
    )
}), fill=T)
EU[,dataset := gsub('_test.csv$', '_train.csv', dataset)]

# Ys <- EU[,list(dataset, y_scale)]
# EU[,y_scale := NULL]

#Load training data scales
YS_FILE <- '~/workspace/data-science-scripts/zach/Ys.rda'
if(!file.exists(YS_FILE)){
  datasets <- yaml.load_file('~/workspace/mbtest-datasets/mbtest_datasets/data/Functionality/OTP/mbtest_data_otp_pure_time_series_with_preds.yaml')
  Ys <- pblapply(datasets, function(x){
    Y <- fread(utils::URLencode(x$dataset_name))[order(as.POSIXct(date)),][['y']]
    Y <- as.numeric(Y)
    Y1 <- Y[1:(N-1)] 
    Y2 <- Y[2:N]
    e = Y1 - Y2
    data.table(
      dataset = x$dataset_name,
      rmse_scale = sqrt(mean(e^2)),
      mad_scale = median(abs(e))
    )
  })
  Ys <- rbindlist(Ys, fill=T)
  Ys[,dataset := gsub('https://s3.amazonaws.com/datarobot_public_datasets/time_series/', '', dataset, fixed=T)]
  saveRDS(Ys, file = YS_FILE)
} else{
  Ys <- readRDS(YS_FILE)
}

#Use best by gini for DR
DR <- DR_mad

#Split out forecast into 3 parts
AR <- FC[method=='Arima',]
ES <- FC[method=='Ets',]
TB <- FC[method=='Tbats',]

#Rename methods
AR <- AR[,method := 'Arima']
ES <- ES[,method := 'Exp.Smooth']
TB <- TB[,method := 'TBATS']
PR <- PR[,method := 'Prophet']
EU <- EU[,method := 'Eureqa']

#Choose datasets that I have for 3 methods and aren't weird
bad_data <- c(
  'incarceration-daily-counts-from-fy-2011-to-june-fy-2016_1_ CDF_FEMALES _train.csv',
  'incarceration-daily-counts-from-fy-2011-to-june-fy-2016_1_ EFFORTS_EX_CONS _train.csv',
  'incarceration-daily-counts-from-fy-2011-to-june-fy-2016_1_ EXTENDED_HOUSE _train.csv'
)
ds <- intersect(DR[,unique(dataset)], FC[,unique(dataset)])
ds <- intersect(ds, PR[,unique(dataset)])
ds <- intersect(ds, EU[,unique(dataset)])
ds <- setdiff(ds, bad_data)
N <- length(ds)

#Subset datasets
skel <- data.table(dataset = unique(ds))
rm(FC)
DR <- merge(DR, skel, all=F)
AR <- merge(AR, skel, all=F)
ES <- merge(ES, skel, all=F)
TB <- merge(TB, skel, all=F)
PR <- merge(PR, skel, all=F)
EU <- merge(EU, skel, all=F)
#EU[is.na(EU)] <- 100

#Setup names
setnames(DR, make.names(names(DR)))
setnames(AR, make.names(names(AR)))
setnames(ES, make.names(names(ES)))
setnames(TB, make.names(names(TB)))
setnames(PR, make.names(names(PR)))
setnames(EU, make.names(names(EU)))

#Combine
method_order <- c(
  'DataRobot',
  'Eureqa',
  'Prophet',
  'TBATS',
  'Arima', 
  'Exp.Smooth'
)
all <- rbindlist(list(DR, AR, ES, TB, PR, EU), fill=T)
all <- all[,method := factor(method, levels=method_order)]

#Make relative
all <- merge(all, Ys, all.x=T, all.y=F, by='dataset')
DR <- merge(DR, Ys, all.x=T, all.y=F, by='dataset')
all <- all[mad_scale > 0 & rmse_scale > 0,]
DR <- DR[mad_scale > 0 & rmse_scale > 0,]
all[, Prediction.Scaled.MAD := Prediction.MAD/(mad_scale)]
all[, Prediction.Scaled.RMSE := Prediction.RMSE/(rmse_scale)]
DR[, Prediction.Scaled.MAD := Prediction.MAD/(mad_scale)]
DR[, Prediction.Scaled.RMSE := Prediction.RMSE/(rmse_scale)]

#Shorter names
all[,dataset := gsub('_train.csv$', '', dataset)]
DR[,dataset := gsub('_train.csv$', '', dataset)]
rm(AR, ES, TB, PR, EU)

#Summary of combined data
summary_data <- all[,list(
    min_smad = min(Prediction.Scaled.MAD),
    pct_25_smad = quantile(Prediction.Scaled.MAD, .25),
    median_smad = median(Prediction.Scaled.MAD),
    mean_smad = mean(Prediction.Scaled.MAD),
    sd_smad = sd(Prediction.Scaled.MAD),
    pct_75_smad = quantile(Prediction.Scaled.MAD, .75),
    max_smad = max(Prediction.Scaled.MAD)
  ), by='method']
summary_data <- summary_data[order(method),]
dr_smad <- summary_data[method=='DataRobot', round(median_smad, 2)]
ar_smad <- summary_data[method=='Arima', round(median_smad, 2)]
es_smad <- summary_data[method=='Exp.Smooth', round(median_smad, 2)]
tb_smad <- summary_data[method=='TBATS', round(median_smad, 2)]
pr_smad <- summary_data[method=='Prophet', round(median_smad, 2)]
eu_smad <- summary_data[method=='Eureqa', round(median_smad, 2)]

#DR Only
DR <- DR[,method := NULL]
oldnames <- names(DR)[grepl('Prediction', names(DR), fixed=TRUE)]
newnames <- paste0('DataRobot.', oldnames)
newnames <- gsub('Prediction', 'Pred', newnames, fixed=T)
newnames <- gsub('Gini.Norm', 'Gini', newnames, fixed=T)
setnames(DR, oldnames, newnames)

#Plotdat
plotdat <- split(all, all[['method']])
plotdat <- plotdat[2:length(plotdat)]
plotdat <- lapply(plotdat, function(x){
  method <- unique(x[['method']])
  if(length(method) != 1){
    stop('Should be one method')
  }
  x[,method := NULL]
  x <- merge(x, DR, by='dataset', all=T)
  print(x)
  x <- x[,Diff := DataRobot.Pred.Scaled.MAD - Prediction.Scaled.MAD]
  x <- x[,list(
    dataset, 
    DataRobot.Pred.Scaled.MAD,
    Prediction.Scaled.MAD,
    Diff
    )]
  #stopifnot('DataRobot.Pred.Scaled.MAD' %in% names(x))
  x <- x[order(-Diff, DataRobot.Pred.Scaled.MAD, -Prediction.Scaled.MAD),]
  setnames(x, 'Prediction.Scaled.MAD', paste0(method, '.Pred.Scaled.MAD'))
  x[,Diff := NULL]
  return(x)
})

#Diffdat
diffdat <- Reduce(function(a,b) merge(a,b,by=c('dataset','DataRobot.Pred.Scaled.MAD'), all=T), plotdat)
keep <- paste0(setdiff(method_order, 'DataRobot'), '.Pred.Scaled.MAD')
diffdat <- diffdat[,c('dataset', keep),with=F]
diffdat <- merge(DR[,list(dataset, DataRobot.Pred.Scaled.MAD)], diffdat, all=T, by='dataset')
diffdat[,DR.Min.Improve := rowMaxs(as.matrix(diffdat[,keep,with=F])) - DataRobot.Pred.Scaled.MAD]
diffdat <- diffdat[order(-DR.Min.Improve, DataRobot.Pred.Scaled.MAD, -Eureqa.Pred.Scaled.MAD, -Prophet.Pred.Scaled.MAD),]

#Checks
diffdat[,mean(DataRobot.Pred.Scaled.MAD < Prophet.Pred.Scaled.MAD)]
diffdat[,mean(DataRobot.Pred.Scaled.MAD < TBATS.Pred.Scaled.MAD)]
diffdat[,mean(DataRobot.Pred.Scaled.MAD < Arima.Pred.Scaled.MAD)]
diffdat[,mean(DataRobot.Pred.Scaled.MAD < Exp.Smooth.Pred.Scaled.MAD)]
```

## Methodology
We compared DataRobot's Out-of-Time Validation (OTV) models to Eureqa, R's Forecast package and Facebook's Prophet package on `r N` datasets. We split these datasets into training sets and test sets, and ran each algorithm on the training set and calculated accuracy on the unseen test set. For DataRobot, we used the test set as a prediction set, so that it was not used by the autopilot for model training or selection. I used the metric "Normalized Gini Score" or "Gini Norm" to compare algorithms, which ranges from -1 (perfectly anti-predictive) to 0 (equivalent to random guessing) to 1 (perfectly predictive).  

With time series problems, we see negative Gini scores more often than with traditional machine learning problems, as models can be fooled by randomness in the time series and end up extrapolating "trends" that do not exist.

We compared DataRobot and Eureqa to a total of 4 open source models: Prophet (from Facebook), auto.arima (from Forecast), ets (automated exponential smoothing from Forecast) and TBATS (a trigonometric function based model from Forecast). Note that all 4 of the open-source forecasting models minimize RMSE, so to keep the comparison fair, I used RMSE as the metric for all DataRobot projects. For each dataset, the DataRobot model with the best Gini Norm on the holdout set was used to make forecasts on the prediction set.

## Results
```{r, echo=FALSE, message=FALSE, fig.align='center'}
ggplot(all, aes(x=method, y=Prediction.Scaled.MAD)) + geom_boxplot() + theme_bw() + scale_y_log10()
```
On average, Eureqa is slightly more accurate than Datarobot (median Gini of `r I(eu_smad)` vs `r I(dr_smad)`). DataRobot is slightly more accurate than Facebook's Prophet package (median Gini of `r I(dr_smad)` vs `r I(pr_smad)`). TBATS is the best model  from the Forecast package, but is typically worse that DataRobot or Prophet (median Gini of `r I(tb_smad)`).
```{r, echo=FALSE, results="asis"}
tbl <- xtable(summary_data, method = "compact", caption = "Summary Results", digits=2, auto=TRUE)
print(tbl, floating = TRUE, booktabs = TRUE, latex.environments = "center", size="\\fontsize{8pt}{6pt}\\selectfont")
```

## Conclusion
DataRobot's OTV models already perform well on a variety of time series problems, and are on average more accurate than all 4 of the open source forecasting models tried. DataRobot does especially well on datasets with complex seasonal patterns, e.g. electricity load, where the hour-of-day pattern may differ in a dramatic (and predictable) way between the winter and summer months. This sort of dynamic seasonality can be extremely difficult for traditional time series models to capture, but is modeled beautifully by DataRobot's "seasonal dummies + XGBoost" approach. DataRobot is also able to make use of covariates, while arima is the only open-source model with this capability.

However, there remains some room for improvement in DataRobot, which can be over-confident based on the holdout set when picking the model to use for forecasting. It might be beneficial to add some heuristics to DataRobot to cause it to prefer simpler models during model selection for time series models. This could help prevent DataRobot from picking complicated models that happen to get lucky in the holdout set but end up extrapolating the wrong trend. On random walk datasets like the S&P 500 stock market data, or the incarceration data, the correct forecast is usually a flat line from the last point (also known as a naive forecast), and the open source models tend to correctly predict this, while DataRobot tends to be overconfident in extrapolating trends.

We could gain additional accuracy in DataRobot, especially on more difficult problems, by adding Eurea and Arima blueprints to the autopilot.
\newpage

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
out <- lapply(plotdat, function(x){
  x_var <- setdiff(names(x), c('dataset', 'Diff', 'DataRobot.Pred.Scaled.MAD'))
  x_title <- gsub('.Pred.Scaled.MAD', '', x_var, fixed=T)
  plt <- ggplot(x, aes_string(x=x_var, y='DataRobot.Pred.Scaled.MAD')) + 
  geom_point() + theme_bw() + geom_abline(slope=1, intercept=0) + 
  geom_text(
    aes(label=dataset), hjust=0, vjust=0, 
    position = position_dodge(width=0.5), size=2) + 
  ggtitle(paste('DataRobot vs', x_title, 'out-of-sample performance')) + 
  scale_x_log10() + scale_y_log10()
  print(plt)
})
```
\newpage

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
tbl <- xtable(diffdat, method = "compact", caption = "Full Results", digits=1, auto=T)
print(tbl, floating = TRUE, booktabs = TRUE, scalebox = 0.65, size="\\fontsize{8pt}{6pt}\\selectfont", floating.environment = 'sidewaystable')
```
